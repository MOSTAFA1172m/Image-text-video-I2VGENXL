# IVGEN-XL: Image + Text to Video Diffusion Model

IVGEN-XL is an advanced model designed for generating videos from image and text inputs. It employs a cascaded architecture, leveraging diffusion processes to produce high-quality and coherent video outputs. This repository provides an easy-to-use Jupyter Notebook to get started with IVGEN-XL.

## Features

- **Multimodal Inputs**: Combines images and text to create dynamic video outputs.
- **Cascaded Architecture**: Utilizes a hierarchical approach to ensure progressively refined video quality.
- **Lightweight Setup**: Run directly in Jupyter Notebook with minimal setup requirements.

## Getting Started

### Requirements

- A Kaggle account for running the notebook on Kaggleâ€™s GPU-enabled environment.
- Basic familiarity with Python and Jupyter Notebooks.

### Steps

1. **Download the Notebook**:

   - Clone the repository or download the `IVGEN-XL.ipynb` file directly.
     ```bash
     git clone https://github.com/MOSTAFA1172m/Image-text-video-IVGENXL.git
     cd IVGEN-XL
     ```

2. **Upload the Notebook to Kaggle**:

   - Go to [Kaggle](https://www.kaggle.com/).
   - Create a new notebook and upload the `IVGEN-XL.ipynb` file.

3. **Enable GPU**:

   - In your Kaggle notebook, navigate to **Settings** > **Accelerator** and select **GPU**.

4. **Install Dependencies**:

   - Run the following command in a code cell:
     ```python
     !pip install -r requirements.txt
     ```

5. **Run the Notebook**:

   - Follow the step-by-step instructions provided in the notebook to input images and text, and generate videos.

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

## Contact

For any questions or feedback, feel free to reach out to [my linkedin](https://www.linkedin.com/in/mostafa-hazem-961931294/).

---

*Note: Ensure the GPU runtime is enabled before running the notebook to avoid performance issues.*

